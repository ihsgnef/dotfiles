\documentclass[10pt]{article}
\title{CMSC711 Midterm}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{graphicx}
\usepackage{float}
\usepackage[margin=1in]{geometry}
\usepackage{fancyhdr}
%\usepackage{charter}
\setlength{\parindent}{0pt}
\setlength{\parskip}{5pt plus 1pt}
\setlength{\headheight}{6pt}
\newcommand\question[2]{\vspace{.1in}\textbf{#1: #2}\vspace{.5em}\vspace{.10in}}
\renewcommand\part[1]{\vspace{.10in}\textbf{(#1)}}
\pagestyle{fancyplain}
\lhead{\textbf{\NAME}}
\chead{\textbf{Midterm}}
\rhead{CMSC711}
\begin{document}\raggedright
\newcommand\NAME{Shi Feng}

\question{1}{Search}

For all protocols, we assume that Bob (or adversary) is ``honest but curious": he
will execute the protocol as is, but might record and explore any data that
Alice sends him. To simplify the answer, false positive documents returned to
Alice are considered as a problem of correctness of the protocol rather than extra
state stored on Alice's side. We only consider word occurrence queries for
correctness, but expand to other for the analysis of supported queries. We
assume that symmetric encryption is secure.

\part{0}
P0 has perfect recall but imperfect precision.
Alice needs to store the keys for symmetric encryption. Bob needs to store the
$m$-bit output of the Bloom Filter for each document, and $r$ hash functions.
The set size $n$ is exponential in the document length.  False positive rate is
$(\frac{m}{n})^r$ when $r=\frac{m}{n}\ln 2$. The storage over head at Bob will
be large in order to get good precision.
Bob has the hash functions, so he can find out what words appear
in each document by enumerating the set of possible words. Because Bloom Filter
ignores word order and duplicate words, this protocol only supports the word
occurrence query. It will have bad precision on phrase query and word occurrence
query with specified number of occurrences.

\part{0a}
Compared to P0, P0a has extra security guarantee that Bob cannot know the
original word occurrence in each document.
It requires extra storage of word hash function for Alice.
Other properties remain the same.

\part{1}
This protocol can correctly return all and only documents containing the search
terms. 
The only storage overhead is the hash functions on Alice's side. 
In terms of security, this is equivalent to a substitution cipher and is
susceptible to frequency analysis.
Since Bob performs string match, this protocol supports any kind of string
matching query, including word occurrence and phrase occurrence.

\part{1a}
Same as P1.

\part{2} 
This protocol can correctly return all and only documents containing search
terms. 
Alice needs to store the keys for symmetric encryption and the word hash
function; Bob needs to store the inverted index. 
Bob knows the occurrences of hashed words in each document, so he can perform
frequency analysis.
This protocol, similar to P0, only supports word occurrence queries.

\part{2a}
The chaff can act as a defense against Bob's frequency analysis.

\part{se}
The computation of the pre-encrypted word $X_i=E_{k''}(W_i)$ and the key of
stream cipher $k_i=f_{k'}(X_i)$ (replace $X_i$ with $L_i$ for scheme 4) are
independent of position, so they can be cached, or pre-computed for the whole
vocabulary.

\newpage
\question{2}{Untrusted Storage}

For computation required for verification, we consider both sides: computing the
function for Bob, and verification for Alice.
One threat model is a third party extracting data from Bob, but we don't
consider it in this question.
Trade-off between storage and computation is possible for some protocols
(computing the checksum each time or storing them), we point them out but
strictly follow the protocol for the analysis. On top of that, we assume that
Alice minimizes her local storage, that is, she won't keep the original data if
it's not necessary for verification.
For secure protocols, by definition Bob needs to store the original data.
For insecure protocols, we analyze the minimum requirements of storage and
computation for both a well-behaved Bob and a cheating Bob.

\part{0}
This protocol is secure.
Both Alice and Bob need to store just the original data.
No computation is required for Bob. Alice needs to verify the data
which is linear time in data size. 
The communication cost for each verification is the size of the original data.

\part{1}
This protocol is not secure, as Bob only needs to store the checksum to pass the
verfication.
Alice only needs to store the checksum.
Both Alice and Bob only need to to store the checksum.
Alice needs to pre-compute the checksum, which is linear in the data size.
The communication cost of each verification equals the size of the checksum.

A well-behaved Bob needs to compute the checksum (linear in data size) for each
verification. A cheating Bob only needs to store the checksum and return it each
time.

\part{2}
This protocol is not secure if Bob knows the number 1024.
Bob can cache the permutations Alice sends and the corresponding
checksums, then he can throw away the original data after the 1024 permutations
are exhausted.
Alice need to pre-compute the 1024 permutations and the corresponding checksums,
she can them store this mapping and throw away the original data.
The communication cost for each verification is the size of a permutation from
Alice to Bob (linear in data size), plus the size of a checksum from Bob to
Alice.

A well-behaved Bob needs to compute the checksum for every permutation recevied
from Alice, which is linear in data size.
A cheating Bob would cache the permutations and the checksums, in addition to
the original data, then throw away the data after seeing 1024 different
permutations.

The security of this protocol can be easily improved by not letting Bob know the
number of permutations: he can only guess when the permutations have been
exhausted. It can also be fixed by re-generating the set of permutations after
the first set is exhausted. But this requires Alice to keep the original data.

\part{2.efficient}
This is not secure because two's complement is independent of sequence so
permutation has no effect on the checksum. Thus Bob can shuffle the data but
still pass the verification.

\part{Schwarz and Miller}
This paper proposed techniques that allow Alice to verify that untrusted
storages faithfully store her data, without her having a local copy.

The algorithm uses two main constructs: signature and parity. The signature is a
compact representation of the data that can detect small changes. The parity of
data blocks is a form of checksum. The calculations of signature and parity can
commute: the signature of party equals the parity of signature. Specifically in
this paper, the signature is the value of a $n$-degree polynomial with data
blocks as coeffecients, the parity is a m/n erasure code where the generator
matrix is obtained by performing Gaussian elimination on a Vandermonde matrix.
Both calculation operates in the same Galois field.

The protocol is: Alice calculate the parity blocks of the original data blocks,
and distribute the blocks to a single or multiple remote storages. Then Alice no
longer need her original copy, she only need the parity generator matrix. For
verification, Alice specify a chunk in the original data and a key $\alpha$, and
the remote storages return the signature of the specified chunk with the given
key. Alice then checks if the parity of the signature blocks equals the
signature of the parity block.

% Although remote storage does not know the parity generation matrix, it may
% construct signatures that match with the parity - one trivial method is to
% return all zero signatures. When there are multiple remote storages, they might
% collude. 

\newpage
\question{3}{CRL Analysis}

\newpage
\question{4}{Ephemeral Data}

One key issue is to find a trusted source of time. Since we cannot rely on a
trusted third-party or Alice herself, the verification of time must be done by
the decryption program running on Bob's computer, potentially with some network
protocol. Hence this program must be protected against Bob's attempts to modify
it, via methods like obfuscation. My assumption is that this protection is
possible - that time can be correctly verified.

The basic idea is to use two keys: $K_1$ encrypts the document, probably
using some symmetric key; $K_2$ encrypts the first key, and the encyrption takes
the expiration time as a parameter. The decryption program $f$ takes the current
time $t$ (which by assumption is correct), the decryption key $K_2$, and
attempts to decrypt. If $t<$ expiration time, it will return $K_1$ which allows
Bobs to decrypt the document, otherwise it should either return nothing or an
invalid key.

Vulnerablility: the decryption program needs (internet) access to a secured
source of time, as Bob can modify his system time as he wants. This secured
source can be the server where Alice stores the data. This can be a point of
attack.

Remark: I understand that the assumption that time can be verified (on Bob) is
quite strong, and not that different from assuming that the decryption program
running on Bob's computer can act as a trusted third-party. The only alternative
scheme I can think of is to have a periodically updated puzzle that must be
solved with update-to-date timestamps. This scheme requiers either 1) Alice or
some trusted third party momentarily, or 2) a protected client-side program,
which is the same as my assumption for the previous scheme.


\newpage
\question{5}{TrInc BlockChain}

There are various methods for double-spending, but the necessary condition is
have to two conflicting transactions, $T_A$ and $T_B$. One case would be, $T_A$
is Alice sending all her bitcoins to her other account; $T_B$ is Alice sending
all her bitcoins to Bob to by USD. Alice will convince Bob of the validity of
$T_B$ so she receives the USD, then (or in parallel) make sure $T_A$ gets
confirmed and written into the block chain.

This is exactly equivocation - Alice tells two parties different things.  The
division of two parties differs in different implementations of double-spending.
In race attack it's $T_A$ and $T_B$ goes to two arbitrary subsets of the bitcoin
network; in Finney attack and majority attack, it's Alice herself, hiding her
own fork that contains $T_A$, versus the rest of the network that sees $T_B$.

Under the current bitcoin protocol, Bob would wait for 6 blocks to confirm
$T_B$, which effectively defends against race and Finney attacks. Majority
attack is still possible. We ignore this delayed confirmation in our solutio,
and the security guarantee does not rely on it.

The general idea of using TrInc to prevent double spending, is to serialize the
transactions of each user and make sure the confirmed transaction history is
continuous. ``Continuous" means ``counter values are incremental".
We need two modifications to the protocol. To simplify, we set number of
counters in each Trinket to one, and assume all counters start with the same
initial value $0$.

First, a transaction needs to be signed and attested by the sender's Trinket, so
all transactions are associated with user-specific counter values. The
``advance" TrInc attestation increments the counter; the data field of one such
attestation can be the hash of the transaction. This attestation is broadcasted
and written to block chain together with the transaction. All nodes can verify
the validity of such transaction - attestation pair.

The second modification is several additional conditions for writing transaction
to blocks, confirmation of transaction, and acceptance of a chain. Requirements
already in Bitcoin protocol, such as not writing conflicting transactions, are
left out.

\begin{itemize}
    \item Additional steps for the confirmation of a set of transactions (size
    might be 1) with the sender: sort the counter value from low to high, only
    consider the prefix where the values are incremental; let $C$ be the
    smallest counter in this unconfirmed set, and $C'$ be the largest counter in
    the confirmed set with the same sender, only consider confirming the
    transaction(s) if $C = C' + 1$, or $C=0$ and $C'=\text{NIL}$.
    \item Reject any block or chain that contains incontinuous history of any
    user, even when the chain is the longer.
    \item The receiver should only confirm a transaction when all previous
    transactions (ordered by counter value) from the sender are written in block
    chain.
\end{itemize}

This protocol doesn't make extra assumption over Bitcoin. It ensures continuity
- or even completeness if we ignore histories before deployment of this
protocol - of user transaction histories in the block chain. It prevents
double-spending. Going back to the two parties of the network that each receives
one of the two conflicting transactions. w.l.o.g assume the counter values
$C_A < C_B$. The party that receives $T_A$ might confirm it. The party that
receives $T_B$ will not confirm before seeing $T_A$, at which point a conflict
will be detected and $T_B$ will be rejected.
If Alice is capable of majority attack, her chain will never be confirmed if it
contains $T_B$, as it either contains $T_A$ which shows conflict, or has
incomplete history with $C_A$ missing.

\end{document}
